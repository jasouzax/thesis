% Theoretical Framework
\section{Theoretical Framework}

This research attempts to solve an issue facing most Visual Sensory Substitution Devices which is primarily about the issue on translating a high bandwidth visual information to low bandwidth audio information without causing overstimulation, our novel solution is the emulate the human sensory mechanism to carry the processing load from the user and ensure that substituted information is minimal and nessary to the user. The theoretical principles includes:

\begin{enumerate}
    \item \textbf{Focus and Spatial Resolution (Foveation)} - The human vision has a tiny high-resolution fovea covering around 1 to 2 degrees of the visual field but accounts for around half of visual cortex \parencite{krantz_2012}, outside this region is a much coarser peripheral vision where acuity drops rapidly \parencite{iwasaki_1986}. \\ Our device attempts to mimic this by using a focus point system where the user can contain the focus radius indicanting that area of the environment the user wants to be translated into audio and at what detail.
    \item \textbf{Selective Attention and Daliency} - Has the visual system cannot process all details at once, it selectively attends to salient or task-relavant features, this is done by implementing a bottom-up saliency and top-down goals to filter out redundant/irrelevant information \parencite{kristjansson_2016}. This is to mean that people focus on key objects ignoring uniform backgrounds as the nervous system "tunes out" repeated stimuli and amplifies novel/focused ones \parencite{gershman_2024}. \\ Has the device translates environmental information, any stagnating/constant information must be tuned out over time leaving behind changes indicating motion.
    \item \textbf{Scene Gist and Gestalt Organization} - Human vision rapidly extract the gist (background) and figures (foreground) from a scene within the first fixation (~36ms) with around 80\% accuracy \parencite{loschky_2025}. This process is done through Gestalt principles that groups elements to simplify complex images such as by similarity, proximity, common region, continuity, etc. \parencite{usertesting_2024} \\ This indicates that the device should be able to generally/primitively seperate the environmental data into background and foreground categories where foreground can then be seperated into groups, this is information to indicate the translated audio.
    \item \textbf{Parallel Motion vs. Detail Pathways}
    \item \textbf{Temporal Dynamics and Scanning}
    \item \textbf{Multisensory Integration}
\end{enumerate}