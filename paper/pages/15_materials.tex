\subsection{Materials and Requirements} % Materials and Equipments

% System Requirements
% = Wireframes both hardware and software interace
%\subsubsection{Materials and Processes}
The World Navigation Hat operates through a multi-stage processing pipeline that begins with data acquisition and culminates in audio feedback delivery. The Orange Pi Zero 2W microcontroller, powered by a 5V/3A UPS module, serves as the central processing unit that orchestrates all system operations. The process initiates with stereo image capture from dual OV5640 USB cameras positioned 10 cm apart, providing 5MP resolution at 160° field of view for photogrammetry operations. Concurrently, the MPU6050 Inertial Measurement Unit tracks head motion and orientation to align the virtual environment with the user's vestibular senses, preventing sensory conflicts. Audio input is captured through an earphone microphone for voice command recognition. Five primary applications run simultaneously on the device:

\begin{enumerate}
    \item Photogrammetry processing that converts 2D stereo images into depth maps and 3D point clouds using stereo disparity calculations
    \item Human visual sense emulation pipeline that implements foveation, selective attention, and scene gist extraction to generate necessary audio cues while minimizing cognitive overload
    \item MediaPipe AI for real-time hand gesture recognition enabling touchless device control
    \item WhisperX voice recognition activated by specific hand gestures for command input
    \item modular framework allowing custom applications to integrate into the main pipeline with connection to the main server through standard APIs
\end{enumerate}
Processed data is transmitted via the SIM868 module (supporting 2G/3G cellular or Wi-Fi connectivity) to a NodeJS server infrastructure that handles additional computational tasks including Ollama for large language model processing, YOLO for advanced object detection, Puppeteer for web automation, external API integration (Google Maps, Meta platforms), SQL database management, and HTTP server operations for client-server communication.

\subsubsection{Hardware Material}
The hardware architecture integrates several critical components optimized for portable wearable computing. The Orange Pi Zero 2W single-board computer features a quad-core ARM Cortex-A53 processor with 512MB/1GB RAM options, providing sufficient computational power for real-time computer vision tasks while maintaining low power consumption suitable for battery operation. Two OV5640 USB cameras serve as the stereo vision system, each delivering 5-megapixel resolution with a 160° field of view and positioned with a 10 cm baseline to enable accurate depth estimation through stereo disparity calculations. The MPU6050 6-axis Inertial Measurement Unit combines a 3-axis gyroscope and 3-axis accelerometer, providing motion tracking data at high refresh rates to synchronize the virtual environment with user head movements. The SIM868 development board integrates GSM/GPRS/GPS functionality, enabling both outdoor navigation through GPS positioning and cellular data connectivity (2G/3G) for server communication when Wi-Fi is unavailable. An Onyehn TRRS audio module facilitates bidirectional audio communication, connecting both speaker output for audio cues and microphone input for voice commands through standard 3.5mm earphone jacks. Power management is handled by a custom UPS module accepting 5V/3A input, featuring lithium battery charging circuits (supporting 18650 or similar rechargeable cells) and voltage regulation to ensure stable operation during mobile use. All components are mounted on a custom-designed hat frame measuring 333.38 mm in length with integrated cable management and component housings to maintain ergonomic comfort during extended wear.

\subsubsection{Software Specification}
The software ecosystem operates across two primary environments: client-side processing on the Orange Pi Zero 2W and server-side operations on a NodeJS platform. The client-side implementation utilizes Python 3.x as the primary programming language, leveraging OpenCV (cv2) for image acquisition, preprocessing, and stereo vision algorithms including stereo calibration, rectification, and disparity map generation. NumPy provides optimized numerical computing for point cloud transformations, matrix operations in photogrammetry calculations (applying the stereo projection matrix Q to depth maps), and efficient array manipulations for real-time processing. Matplotlib enables visualization during development and debugging phases, generating spectrograms for audio cue analysis and 3D scatter plots for point cloud verification. MediaPipe framework implements hand gesture recognition through pre-trained machine learning models optimized for mobile deployment, detecting key hand landmarks and classifying gestures with minimal latency. PyTorch serves as the deep learning backend for custom neural network implementations, including depth estimation refinement models and audio generation networks that emulate human auditory processing. Additional Python libraries include SciPy for signal processing (audio synthesis, filtering), librosa for audio feature extraction, and pyserial for communication with peripheral modules (SIM868, MPU6050). The server-side infrastructure runs NodeJS with Express framework for HTTP server operations, handling REST API endpoints for client requests, managing WebSocket connections for real-time bidirectional communication, and coordinating database operations through SQL query execution. Ollama integration enables on-device large language model inference for natural language understanding and context-aware assistance, while YOLO (You Only Look Once) models provide high-speed object detection and classification when additional visual recognition is required beyond the client-side capabilities. Puppeteer automates web browser interactions, enabling the device to fetch real-time information from web services and interact with digital environments for enhanced navigation support.
The development workflow integrates multiple productivity and collaboration tools to streamline project organization, documentation, and version control. Visual Studio Code (VSCode) serves as the primary integrated development environment (IDE), providing syntax highlighting for Python and JavaScript, integrated terminal access for remote SSH connections to the Orange Pi Zero 2W, Git integration for version control operations, and extensive extension support including Python linters (pylint, flake8), formatters (black, autopep8), and remote development extensions for direct editing on embedded systems. GitHub hosts the project repositories, implementing version control through Git for both client-side Python applications and server-side NodeJS code, facilitating collaborative development among team members through branch management, pull requests, code reviews, and issue tracking for bug reports and feature requests. LaTeX document preparation system generates the formal thesis documentation with precise mathematical typesetting for equations including stereo disparity formulas, point cloud projection matrices, and depth-to-audio mapping functions, ensuring professional formatting standards for academic submission while maintaining version-controlled .tex source files. Google Docs provides real-time collaborative editing for preliminary research documentation, literature review organization, meeting notes, and draft content development, enabling simultaneous multi-user editing with comment threads for peer feedback and revision tracking. Microsoft Office suite (Word, Excel, PowerPoint) supports supplementary documentation tasks including formatted research proposals, data analysis spreadsheets for experimental results (accuracy measurements, user feedback surveys, performance benchmarks), and presentation materials for design reviews and project demonstrations. Claude AI assists throughout the development lifecycle as an AI-powered coding assistant and research tool, providing algorithm optimization suggestions, debugging support for complex stereo vision calculations, documentation generation for API endpoints and function specifications, literature synthesis for theoretical framework development, and technical writing refinement for thesis chapters. This integrated software toolchain ensures systematic project management from initial concept through final implementation, maintaining code quality through version control, facilitating team collaboration across distributed work environments, and producing comprehensive documentation that meets both academic standards and technical reproducibility requirements.

\subsubsection{Library and Board Managers}
Development and deployment require specific software dependencies managed through multiple package systems across different platforms. For the Orange Pi Zero 2W running Armbian or Ubuntu-based distributions, the APT package manager handles system-level dependencies including Python 3.x development packages (python3-dev, python3-pip), OpenCV system libraries (libopencv-dev, python3-opencv), audio system requirements (libasound2-dev, portaudio19-dev), and USB camera support utilities (v4l-utils). Python package management through pip3 installs critical libraries with specific version constraints: opencv-python ($\geq 4.5.0$) for computer vision operations, numpy ($\geq 1.21.0$) for numerical computing, mediapipe ($\geq 0.8.0$) for hand tracking AI models, torch ($\geq 1.10.0$) with ARM-compatible builds for deep learning inference, sounddevice and soundfile for audio I/O operations, pyserial ($\geq 3.5$) for hardware communication, and requests for HTTP client functionality. Arduino IDE or Platform IO manages firmware for any auxiliary microcontrollers if implemented, including board definitions for custom boards and library dependencies for sensor communication protocols (I2C for MPU6050, SPI for peripheral modules). The NodeJS ecosystem uses npm (Node Package Manager) to install server-side dependencies: express ($\geq 4.18.0$) for web server framework, ws for WebSocket implementation, sequelize or knex for SQL database ORM, axios for HTTP client operations to external APIs, and child\_process management for spawning Ollama and YOLO processes. Board-specific configurations require Orange Pi GPIO libraries (OrangePi.GPIO or wiringOP) for direct hardware pin control if needed, and kernel module loading for camera interfaces (ensuring proper v4l2 driver support for OV5640 USB cameras through modprobe configurations). Git version control manages source code across development iterations, with repositories configured for both client and server codebases, while systemd service configurations enable automatic startup of critical applications on boot for production deployment.

\subsubsection{Other Materials/Equipment/Devices}
Beyond the core electronic components, the project requires supplementary materials and equipment for fabrication, testing, and evaluation. The physical enclosure utilizes 3D-printed components designed in CAD software, with wireframe dimensions of 333.38 mm length, 197.50 mm width, and component-specific mounting features including camera housings with precise 10 cm spacing alignment, ventilated sections for heat dissipation from processing components, and cable routing channels. The 3D printing process uses PLA or PETG filament for structural components requiring strength and thermal stability, with print settings optimized for layer adhesion and surface finish to ensure user comfort during extended wear. A standard baseball cap or adjustable hat frame serves as the foundation for component integration, providing familiar ergonomics and adjustable sizing through standard strap mechanisms. Micro SD card (minimum 32GB Class 10 or UHS-I) stores the operating system, application code, and temporary data cache for the Orange Pi Zero 2W, while a micro SIM card with active data plan enables cellular connectivity through the SIM868 module. Lithium-ion battery cells (18650 format, 3.7V nominal, minimum 2500mAh capacity) power the UPS module, with appropriate battery holders and spot-welded connections ensuring reliable electrical contact and mechanical stability. USB-C cable provides charging interface for the UPS module, allowing users to recharge using standard mobile phone chargers or power banks. Testing and evaluation equipment includes a reference measuring device (laser rangefinder or calibrated ruler) for depth accuracy validation, comparing predicted distances from stereo disparity calculations against ground truth measurements across various ranges (0.5m to 5m typical operating distance). A standardized navigation course with marked obstacles, varying textures, and elevation changes facilitates user testing protocols for evaluating device effectiveness. Audio analysis equipment (reference microphone, audio interface, spectrum analyzer software) characterizes the generated audio cues for frequency response, dynamic range, and spatial positioning accuracy. Additionally, development workstations (laptop/desktop computers with Linux or Windows OS) run cross-compilation toolchains, debugging interfaces (SSH, serial console), and simulation environments for algorithm validation before hardware deployment. Safety equipment for user testing includes protective padding for obstacle courses, first aid supplies, and emergency communication devices in compliance with IRB-approved testing protocols outlined in the ethical considerations section.